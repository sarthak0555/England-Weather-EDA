{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "R_xAiF9fp47y"
   },
   "outputs": [],
   "source": [
    "import pandas as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3Q-2zLAAnKH3"
   },
   "outputs": [],
   "source": [
    "with open('/time_series_1.pickle', 'rb') as handle:\n",
    "  time_series_1 = pickle.load(handle)\n",
    "\n",
    "with open('/time_series_2.pickle', 'rb') as handle:\n",
    "  time_series_2 = pickle.load(handle)\n",
    "\n",
    "with open('/y.pickle', 'rb') as handle:\n",
    "  y = pickle. load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNl0FnulqRqZ",
    "outputId": "cce67820-83b6-4f42-90db-25c1093bcdcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30, 29, 29, ..., 36, 35, 50],\n",
       "       [31, 31, 30, ..., 37, 32, 31],\n",
       "       [28, 28, 28, ..., 40, 29, 38],\n",
       "       ...,\n",
       "       [28, 28, 28, ..., 38, 28, 36],\n",
       "       [28, 28, 29, ..., 31, 36, 51],\n",
       "       [31, 31, 30, ..., 35, 38, 24]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVEJ96bVqe6c",
    "outputId": "28d8fe14-582b-46ed-c7ac-af80ea328ac5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[84, 72, 93, ...,  2,  2,  1],\n",
       "       [71, 83, 81, ...,  1,  1,  1],\n",
       "       [78, 71, 82, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [83, 72, 95, ...,  0,  0,  0],\n",
       "       [84, 68, 92, ...,  1,  0,  0],\n",
       "       [81, 71, 98, ...,  0,  0,  0]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sd46sjGSqkTk",
    "outputId": "1fe25b65-396e-46e4-9845-ab47235ecc65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., ..., 3., 3., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TETfegStsvfu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combine time series data\n",
    "X = np.stack((time_series_1, time_series_2), axis=-1)\n",
    "\n",
    "# Convert y to one-hot encoding\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HK8fpxXbDl_w"
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gp7--14lDwoo"
   },
   "outputs": [],
   "source": [
    "# Define batch size and shuffle buffer size\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sTu0OpHfDpLr"
   },
   "outputs": [],
   "source": [
    "# Create a TensorFlow dataset from the train set\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(shuffle_buffer_size).batch(batch_size)\n",
    "\n",
    "# Create a TensorFlow dataset from the test set\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "w1hOQXxus0gz"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=5, activation='relu', input_shape=(5000, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.SimpleRNN(units=64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(units=128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True),\n",
    "    tf.keras.layers.GRU(units=64, dropout=0.2, recurrent_dropout=0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# For creating the checkpoint for out model so that we can save the optimal model.\n",
    "filepath=\"/content/drive/MyDrive/workspace/sarthak/complex_model.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\", verbose=1, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ot5c_qUds3cS",
    "outputId": "0d5f9ccd-3d40-4b06-cf7f-29a2c131e8bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3863 - accuracy: 0.2681 \n",
      "Epoch 1: val_loss improved from inf to 1.38808, saving model to /content/drive/MyDrive/workspace/sarthak/complex_model.hdf5\n",
      "100/100 [==============================] - 1184s 12s/step - loss: 1.3863 - accuracy: 0.2681 - val_loss: 1.3881 - val_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3631 - accuracy: 0.3063 \n",
      "Epoch 2: val_loss did not improve from 1.38808\n",
      "100/100 [==============================] - 1167s 12s/step - loss: 1.3631 - accuracy: 0.3063 - val_loss: 1.3992 - val_accuracy: 0.2600\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3098 - accuracy: 0.3606 \n",
      "Epoch 3: val_loss improved from 1.38808 to 1.32165, saving model to /content/drive/MyDrive/workspace/sarthak/complex_model.hdf5\n",
      "100/100 [==============================] - 1167s 12s/step - loss: 1.3098 - accuracy: 0.3606 - val_loss: 1.3216 - val_accuracy: 0.3300\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2324 - accuracy: 0.4294 \n",
      "Epoch 4: val_loss improved from 1.32165 to 1.14906, saving model to /content/drive/MyDrive/workspace/sarthak/complex_model.hdf5\n",
      "100/100 [==============================] - 1163s 12s/step - loss: 1.2324 - accuracy: 0.4294 - val_loss: 1.1491 - val_accuracy: 0.4613\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.1649 - accuracy: 0.4638 \n",
      "Epoch 5: val_loss improved from 1.14906 to 1.08229, saving model to /content/drive/MyDrive/workspace/sarthak/complex_model.hdf5\n",
      "100/100 [==============================] - 1177s 12s/step - loss: 1.1649 - accuracy: 0.4638 - val_loss: 1.0823 - val_accuracy: 0.5063\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.1056 - accuracy: 0.5034 \n",
      "Epoch 6: val_loss improved from 1.08229 to 0.92255, saving model to /content/drive/MyDrive/workspace/sarthak/complex_model.hdf5\n",
      "100/100 [==============================] - 1197s 12s/step - loss: 1.1056 - accuracy: 0.5034 - val_loss: 0.9226 - val_accuracy: 0.6100\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.0274 - accuracy: 0.5575 \n",
      "Epoch 7: val_loss improved from 0.92255 to 0.90631, saving model to /content/drive/MyDrive/workspace/sarthak/complex_model.hdf5\n",
      "100/100 [==============================] - 1182s 12s/step - loss: 1.0274 - accuracy: 0.5575 - val_loss: 0.9063 - val_accuracy: 0.6150\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9822 - accuracy: 0.5703 \n",
      "Epoch 8: val_loss did not improve from 0.90631\n",
      "100/100 [==============================] - 1199s 12s/step - loss: 0.9822 - accuracy: 0.5703 - val_loss: 0.9163 - val_accuracy: 0.6062\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9308 - accuracy: 0.5978 \n",
      "Epoch 9: val_loss improved from 0.90631 to 0.75254, saving model to /content/drive/MyDrive/workspace/sarthak/complex_model.hdf5\n",
      "100/100 [==============================] - 1174s 12s/step - loss: 0.9308 - accuracy: 0.5978 - val_loss: 0.7525 - val_accuracy: 0.7025\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8404 - accuracy: 0.6431 \n",
      "Epoch 10: val_loss improved from 0.75254 to 0.71087, saving model to /content/drive/MyDrive/workspace/sarthak/complex_model.hdf5\n",
      "100/100 [==============================] - 1179s 12s/step - loss: 0.8404 - accuracy: 0.6431 - val_loss: 0.7109 - val_accuracy: 0.7200\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=10, validation_data=test_dataset, verbose = 1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M6tpPRbEU6Ss",
    "outputId": "c9e998c7-635d-4f22-a05a-ec577772d5f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 32s 1s/step - loss: 0.7109 - accuracy: 0.7200\n",
      "Test accuracy 0.7200000286102295\n",
      "Test loss 0.7108709216117859\n"
     ]
    }
   ],
   "source": [
    " test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print('Test accuracy',test_acc)\n",
    "print('Test loss',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jhfXIAe1-rA-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
