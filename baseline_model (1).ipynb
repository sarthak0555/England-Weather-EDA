{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubfGqe3BPFUG"
   },
   "source": [
    "**1. Discuss what type of sequence prediction approach (sequence-to-vector, sequence-to-sequence, or encoder-decoder) is most sensible to predict the operating mode of a turbine based on the two sensor reading time series. Also describe what data shape you need to use for your chosen approach.**\n",
    "\n",
    "The most sensible approach for predicting the operating mode of a turbine based on the two sensor reading time series would be a sequence-to-vector approach. This is because we have two time series inputs (time_series_1 and time_series_2), and we want to predict a single output (operating mode) for each time series pair.\n",
    "\n",
    "\n",
    "For this approach, we could use a combination of 1D convolutional layers (Conv1D) and recurrent layers (such as LSTM or GRU) to capture the patterns in the time series data. The final output of the model would be a dense layer with softmax activation to predict the operating mode (0, 1, 2, or 3).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxGekMgGX-Kw"
   },
   "source": [
    "**4. We have come across Conv1D layers as a tool for analyzing time series. Different from recurrent layers such as SimpleRNN, LSTM, or GRU, when we apply a Conv1D layer to a part of a sequence, the operation does not depend on the application of the layer to previous parts of the sequence. Discuss in which types of (business) applications ConviD layers can be particularly useful, and in which you should prefer a recurrent layer.**\n",
    "\n",
    "\n",
    "**Conv1D layers** can be particularly useful in (business) applications where there are:\n",
    "\n",
    "\n",
    "**Signal processing**: Conv1D layers can help in analyzing and processing audio signals, sensor data, and other one-dimensional signals.\n",
    "**Text analysis**: When it comes to images, the filters of a 2D convolution layer move across both the height and width dimensions. However, Conv1D only traverses a single axis, making it appropriate for applying convolution to sequential data, such as text or signals. Consequently, using Conv1D for these types of data makes perfect sense.\n",
    "\n",
    "\n",
    "**We should prefer a recurrent layer in situations where**:\n",
    "**Prediction problems**\n",
    "\n",
    "When it comes to solving prediction problems involving sequences, Recurrent Layers are typically very useful. Sequence prediction problems can take many forms and are typically characterized by the types of inputs and outputs that they involve.\n",
    "\n",
    "**Machine Translation**\n",
    "\n",
    "In the case of machine translation, some form of Recurrent Layer can be leveraged to translate text from one language to another. Almost all modern translation systems incorporate some advanced variant of a Recurrent Neural Network (RNN). In this setup, the source language can serve as the input, while the desired output will be the corresponding text in the target language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "R_xAiF9fp47y"
   },
   "outputs": [],
   "source": [
    "import pandas as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3Q-2zLAAnKH3"
   },
   "outputs": [],
   "source": [
    "with open('/time_series_1.pickle', 'rb') as handle:\n",
    "  time_series_1 = pickle.load(handle)\n",
    "\n",
    "with open('/time_series_2.pickle', 'rb') as handle:\n",
    "  time_series_2 = pickle.load(handle)\n",
    "\n",
    "with open('/y.pickle', 'rb') as handle:\n",
    "  y = pickle. load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNl0FnulqRqZ",
    "outputId": "f09213a3-6c33-4252-8c7a-1f71add00ab7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30, 29, 29, ..., 36, 35, 50],\n",
       "       [31, 31, 30, ..., 37, 32, 31],\n",
       "       [28, 28, 28, ..., 40, 29, 38],\n",
       "       ...,\n",
       "       [28, 28, 28, ..., 38, 28, 36],\n",
       "       [28, 28, 29, ..., 31, 36, 51],\n",
       "       [31, 31, 30, ..., 35, 38, 24]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVEJ96bVqe6c",
    "outputId": "73baab6e-e510-4dc0-8504-85c4d76e7c94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[84, 72, 93, ...,  2,  2,  1],\n",
       "       [71, 83, 81, ...,  1,  1,  1],\n",
       "       [78, 71, 82, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [83, 72, 95, ...,  0,  0,  0],\n",
       "       [84, 68, 92, ...,  1,  0,  0],\n",
       "       [81, 71, 98, ...,  0,  0,  0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sd46sjGSqkTk",
    "outputId": "a6a8cd3b-95df-4deb-86fe-ca80634d501f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., ..., 3., 3., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "H6lIoXam4CnO"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Combine time series data\n",
    "X = np.stack((time_series_1, time_series_2), axis=-1)\n",
    "\n",
    "# Convert y to one-hot encoding\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HK8fpxXbDl_w"
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gp7--14lDwoo"
   },
   "outputs": [],
   "source": [
    "# Define batch size and shuffle buffer size\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "sTu0OpHfDpLr"
   },
   "outputs": [],
   "source": [
    "# Create a TensorFlow dataset from the train set\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(shuffle_buffer_size).batch(batch_size)\n",
    "\n",
    "# Create a TensorFlow dataset from the test set\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3FdkN4eQH28"
   },
   "source": [
    "## **Baseline Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "w1hOQXxus0gz"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=5, activation='relu', input_shape=(5000, 2)),\n",
    "    tf.keras.layers.SimpleRNN(units=64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True),\n",
    "    tf.keras.layers.GRU(units=64, dropout=0.2, recurrent_dropout=0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# For creating the checkpoint for out model so that we can save the optimal model.\n",
    "filepath=\"/content/drive/MyDrive/workspace/sarthak/baseline_model.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ot5c_qUds3cS",
    "outputId": "cc979096-5aee-4503-f83f-625bc26f4269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3843 - accuracy: 0.2853 \n",
      "Epoch 1: val_loss improved from inf to 1.33122, saving model to /content/drive/MyDrive/workspace/sarthak/baseline_model.hdf5\n",
      "100/100 [==============================] - 1614s 16s/step - loss: 1.3843 - accuracy: 0.2853 - val_loss: 1.3312 - val_accuracy: 0.3663\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3459 - accuracy: 0.3319 \n",
      "Epoch 2: val_loss improved from 1.33122 to 1.26288, saving model to /content/drive/MyDrive/workspace/sarthak/baseline_model.hdf5\n",
      "100/100 [==============================] - 1622s 16s/step - loss: 1.3459 - accuracy: 0.3319 - val_loss: 1.2629 - val_accuracy: 0.4425\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3080 - accuracy: 0.3731 \n",
      "Epoch 3: val_loss improved from 1.26288 to 1.20639, saving model to /content/drive/MyDrive/workspace/sarthak/baseline_model.hdf5\n",
      "100/100 [==============================] - 1620s 16s/step - loss: 1.3080 - accuracy: 0.3731 - val_loss: 1.2064 - val_accuracy: 0.4638\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2450 - accuracy: 0.4347 \n",
      "Epoch 4: val_loss improved from 1.20639 to 1.14991, saving model to /content/drive/MyDrive/workspace/sarthak/baseline_model.hdf5\n",
      "100/100 [==============================] - 1609s 16s/step - loss: 1.2450 - accuracy: 0.4347 - val_loss: 1.1499 - val_accuracy: 0.4825\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.1639 - accuracy: 0.4737 \n",
      "Epoch 5: val_loss improved from 1.14991 to 1.04266, saving model to /content/drive/MyDrive/workspace/sarthak/baseline_model.hdf5\n",
      "100/100 [==============================] - 1570s 16s/step - loss: 1.1639 - accuracy: 0.4737 - val_loss: 1.0427 - val_accuracy: 0.5450\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.0952 - accuracy: 0.5147 \n",
      "Epoch 6: val_loss improved from 1.04266 to 1.02201, saving model to /content/drive/MyDrive/workspace/sarthak/baseline_model.hdf5\n",
      "100/100 [==============================] - 1579s 16s/step - loss: 1.0952 - accuracy: 0.5147 - val_loss: 1.0220 - val_accuracy: 0.5725\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.0330 - accuracy: 0.5447 \n",
      "Epoch 7: val_loss improved from 1.02201 to 0.91828, saving model to /content/drive/MyDrive/workspace/sarthak/baseline_model.hdf5\n",
      "100/100 [==============================] - 1579s 16s/step - loss: 1.0330 - accuracy: 0.5447 - val_loss: 0.9183 - val_accuracy: 0.5962\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9453 - accuracy: 0.5878 \n",
      "Epoch 8: val_loss improved from 0.91828 to 0.80428, saving model to /content/drive/MyDrive/workspace/sarthak/baseline_model.hdf5\n",
      "100/100 [==============================] - 1567s 16s/step - loss: 0.9453 - accuracy: 0.5878 - val_loss: 0.8043 - val_accuracy: 0.6637\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8707 - accuracy: 0.6309 \n",
      "Epoch 9: val_loss improved from 0.80428 to 0.73519, saving model to /content/drive/MyDrive/workspace/sarthak/baseline_model.hdf5\n",
      "100/100 [==============================] - 1568s 16s/step - loss: 0.8707 - accuracy: 0.6309 - val_loss: 0.7352 - val_accuracy: 0.6750\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7959 - accuracy: 0.6634 \n",
      "Epoch 10: val_loss did not improve from 0.73519\n",
      "100/100 [==============================] - 1586s 16s/step - loss: 0.7959 - accuracy: 0.6634 - val_loss: 0.8038 - val_accuracy: 0.6612\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=10, validation_data=test_dataset, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rPTmXI7TTWps",
    "outputId": "bff35e81-c0f3-47af-c730-2d9ca283c7d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 35s 1s/step - loss: 0.8038 - accuracy: 0.6612\n",
      "Test accuracy 0.6612499952316284\n",
      "Test loss 0.803802490234375\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print('Test accuracy', test_acc)\n",
    "print('Test loss', test_loss)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
